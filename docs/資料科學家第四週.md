# 資料科學家第四週

## 「尺度」的回顧複習與定義加深
* 名目尺度
  - **無法**使用**加減乘除**處理
  - 只能計算**次數**以及累積百分比
  - 屬**質**的，**定性**資料
  - 又稱**類別尺度**
  - Ex：婚姻狀況、性別、單眼皮雙眼皮

  > 注意! ID : 定義資料的唯一編號：此為**名目尺度**

* 數值型(連續尺度)
  - **能夠**使用**加減乘除**處理
  - 屬**量**的，**定量**資料
  - 又稱**數值尺度**
  - Ex：身高、體重、收入、距離

## 資料的身分證
* 資料說明檔內的必要內容
  1. 欄位名稱
  2. 欄位說明
  3. 資料型態

## 決策樹常見的三大演算法

### CART (Classification And Regression Tree)
* 又名分類與迴歸樹
* 美國統計學家 **布萊曼Brieman** 於1984年提出
* 每次都產生兩個子節點
* 應變數(目標變數)與自變數不限制其變數類型
* 使用Gini Index


### ID3 (Iterative Dichotomiser 3)
* 澳洲研究者昆蘭Quinlan於1986年提出
* 奧卡姆剃刀的理論基礎
  - 月是小型的決策樹越優於大型的決策樹(簡單理論)
  - 使用Information Entropy的概念
* 使用所有沒有使用的屬性並計算與之相關的樣本Entropy值
* 選取其中Entropy值最小的屬性
* 生成包含該屬性的節點

### C4.5
* 澳洲研究者昆蘭Quinlan於1993年提出
* 為ID3演算法的擴展版，可以同時處理名目尺度與連續尺度
* 使用Entropy
* 分割不限二元

## 決策樹演算法在 WEKA 上的實作
* 可以分析數值型資料
  - Weka.classifiers.trees.J48
  > C4.5用JAVA語言所寫的第八個版本
* 只能分析非數值型資料
  - Weka.classifiers.trees.ID3

## Test Options
* Use training set (訓練資料集)
* Supplied test set (測試驗證資料集)
* Cross-validation
  - Folds : 10 ( 代表1/10做驗證，並交叉應用 )
* Percentage split
  - % : 70 ( 代表全部的70%做訓練建模，其餘做測試驗證 )

## 極端案例 Leave one out
* 交叉驗證的次數 == 資料集的筆數

## Cross Validation
* pros
  - 將可以作為訓練集的資料量使用最大化
  - 測試集和訓練集完全互斥
  - 涵蓋所有的資料而使得結果具有代表性
* cons
  - 計算次數過多，運算的成本過高
  - 因為每次只有一個測試資料集，因此估計的變異也會過高

## Classifier output
* Run Information

|項目|說明|
|---|---|
|Scheme|使用的演算法|
|Relation|使用的資料集|
|Instances|資料集內的資料筆數|
|Attributes|資料集內的變數總數、清單列表|
|Test mode|使用的測試選項 (Test option)|

* Classifier model ( full training set )

|項目|說明|
|---|---|
|tree|文字模式下的樹狀圖 (略)|
|Number of Leaves|葉子數量 (無子葉的終結點)|
|Size of the tree|所有節點數量 (包含root、all parent、all child)|
|Time taken to build model|使用訓練資料集的**建模耗費時間(秒)**|

* Evaluation on test split

|項目|說明|
|---|---|
|Time taken to test model on training split|使用測試資料集的驗證耗費時間(秒)|

* Summary

|項目|說明|
|---|---|
|Correctly Classified Instances|分類正確數量、分類正確率|
|Incorrectly Classified Instances|分類錯誤數量、分類錯誤率|
|Kappa statistic||
|Mean absolute error||
|Root mean squared error||
|Relative absolute error||
|Root relative squared error||
|Total Number of Instances||

* Detailed Accuracy By Class

||TP Rate|FP Rate|Precision|Recall| F-Measure|MCC|ROC Area|PRC Area|Class|
|---|---|---|---|---|---|---|---|---|---|
||?|?|?|?|?|?|?|?|是 True|
||?|?|?|?|?|?|?|?|否 False|
|Weighted Avg.|?|?|?|?|?|?|?|?||

* **Confusion Matrix (含混矩陣)**
  - 用意在於判斷一顆決策樹好或不好

|a|b| <-- classified as|
|---|---|---|
|245|29|a|
|17|309|b|
> * 決策樹認為是 a 類別而資料確實是 a 類別的數量有 245 筆
* 決策樹認為是 b 類別而資料實際是 a 類別的數量有 29 筆
* 決策樹認為是 a 類別而資料實際是 b 類別的數量有 17 筆
* 決策樹認為是 b 類別而資料確實是 b 類別的數量有 309 筆
> > 取 Confusion Matrix 計算絕對值，值越大表示樹越好，值越小表示樹越差

## Result list (right-click for options)
* 結果列表清單

||時間|建模技術|演算法|
|---|---|---|---|
|範例1|17:33:24|tree|J48|
|解讀1|下午五點半|使用分類樹|C4.5用JAVA語言所寫的第八個版本|

* 滑鼠右鍵功能選單

|項目|說明|
|---|---|
|View in main window||
|View in separate window||
|Save result buffer||
|Delete result buffer||
|---|---|
|Load model|讀取建立好的模型|
|Save model|儲存建立好的模型|
|**Re-evaluate model on current test set**|用現在現有的這個模型，重新的去評估跟測試新的測試資料集|
|Re-apply this model's configuration||
|---|---|
|Visualize classsifier errors||
|Visualize tree||
|Visualize margin curve||
|Visualizethreshold curve||
|CosstBenefit analysis||
|Visualize cost curve||

## 補充與注意事項
* 測試資料集 ---要去配合---> 訓練資料集
* 訓練資料集與測試資料集的資料型別需相同，否則會有不相容的狀況無法執行
*
